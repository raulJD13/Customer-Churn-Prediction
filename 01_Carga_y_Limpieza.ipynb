{"cells":[{"cell_type":"markdown","metadata":{"id":"2L2cQggQt6zD"},"source":["# Carga y limpieza de datos\n","https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22455,"status":"ok","timestamp":1762185188897,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"qZ_d9clkrYY3","outputId":"c9ba1012-3e8a-4ecf-fa1d-ddedc85dbe1c"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.14.0' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"LubCIqgZvXw4"},"source":["# Paso 1: Define tus rutas\n","Primero, definamos las variables para tus carpetas. Esto hace que tu código sea mucho más limpio y fácil de mantener."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1762185188898,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"MlVcG9SrvYOG"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.14.0' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["# --- 1. Definir Rutas (CORREGIDO) ---\n","\n","# Ruta base de tu proyecto\n","BASE_DIR = \"/content/drive/My Drive/AI Projects/Customer Churn/\"\n","\n","# Carpeta donde están los datos\n","DATA_DIR = BASE_DIR + \"datasets/\"\n","\n","# Ruta AL ARCHIVO .zip (¡Esta es la corrección!)\n","# El archivo .zip está DENTRO de la carpeta datasets\n","ZIP_FILE = DATA_DIR + \"brazilian-ecommerce.zip\"\n"]},{"cell_type":"markdown","metadata":{"id":"u8WpsJ9tvmde"},"source":["# Paso 2: Descomprime el archivo .zip\n","Ahora, usa un comando de Linux (!unzip) para descomprimir los archivos en la carpeta datasets que acabas de definir.\n","\n","! le dice a Colab que ejecute un comando de terminal.\n","\n","-q significa \"quiet\" (silencioso), para que no te muestre los 100.000 archivos mientras descomprime.\n","\n","-d especifica el directorio de destino."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4331,"status":"ok","timestamp":1762185193226,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"cRYi-qq6vms1","outputId":"cb72a079-1831-415a-957b-6d7b27e07f20"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.14.0' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["# --- 2. Descomprimir los datos ---\n","\n","print(f\"Descomprimiendo {ZIP_FILE} en {DATA_DIR}...\")\n","\n","# Usamos -n para evitar descomprimir si ya existen (no sobreescribir)\n","!unzip -q -n \"{ZIP_FILE}\" -d \"{DATA_DIR}\"\n","\n","print(\"¡Descompresión completada!\")"]},{"cell_type":"markdown","metadata":{"id":"mf79ckCSv6xZ"},"source":["# Paso 3: Verifica los archivos\n","Comprobemos que los archivos .csv están donde esperamos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77,"status":"ok","timestamp":1762185193304,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"E7N1tQyPv7An","outputId":"3968b8e5-649b-46fd-af20-5ffbf0df7d5c"},"outputs":[],"source":["# --- 3. Verificar los archivos ---\n","# Deberías ver una lista de todos los .csv (ej: olist_customers_dataset.csv, etc.)\n","\n","!ls \"{DATA_DIR}\""]},{"cell_type":"markdown","metadata":{"id":"UfUMOAcw0f7D"},"source":["# Paso 4: Cargar y Entender los Datos\n","1. Cargar todos los CSVs en DataFrames\n","Vamos a cargar todos los archivos en pandas y a darles nombres lógicos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9764,"status":"ok","timestamp":1762185203077,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"jZG02qLM1GqA","outputId":"85034d2f-ea1f-4f81-99c9-6b65c495b002"},"outputs":[],"source":["# --- 4. Cargar todos los datasets ---\n","import pandas as pd\n","import os # Para unir rutas de forma limpia\n","\n","# Carga todos los archivos .csv en un diccionario de DataFrames\n","# Esto es más limpio que tener 9 variables separadas\n","\n","dataframes = {} # Un diccionario para guardar cada df\n","files_to_load = [\n","    \"olist_customers_dataset.csv\",\n","    \"olist_geolocation_dataset.csv\",\n","    \"olist_order_items_dataset.csv\",\n","    \"olist_order_payments_dataset.csv\",\n","    \"olist_order_reviews_dataset.csv\",\n","    \"olist_orders_dataset.csv\",\n","    \"olist_products_dataset.csv\",\n","    \"olist_sellers_dataset.csv\",\n","    \"product_category_name_translation.csv\"\n","]\n","\n","print(\"Cargando archivos...\")\n","for file in files_to_load:\n","    # Quita el \".csv\" y el \"olist_\" para crear un nombre de clave limpio\n","    key_name = file.replace(\"olist_\", \"\").replace(\"_dataset.csv\", \"\").replace(\".csv\", \"\")\n","\n","    file_path = os.path.join(DATA_DIR, file) # os.path.join es más robusto que usar \"+\"\n","\n","    try:\n","        dataframes[key_name] = pd.read_csv(file_path)\n","        print(f\"  ✅ Cargado: {file} (como dataframes['{key_name}'])\")\n","    except FileNotFoundError:\n","        print(f\"  ❌ Error: No se encontró {file_path}. Verifica tus rutas.\")\n","\n","print(\"\\n¡Carga completada!\")"]},{"cell_type":"markdown","metadata":{"id":"VOx5JfAq1gaV"},"source":["# El Primer \"Merge\" (Unión)\n","## 1. DataFrame de Pedidos (orders):"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1762185203078,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"BMu_SoEB1pFp","outputId":"fedfa254-f2eb-450f-872f-6c513d8e2aa6"},"outputs":[],"source":["df_orders = dataframes['orders']\n","print(\"Columnas de Pedidos:\")\n","print(df_orders.columns.tolist())"]},{"cell_type":"markdown","metadata":{"id":"1sKbQUaC2TZX"},"source":["## DataFrame de Clientes (customers):"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1762185203096,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"2VSRllPv2SU6","outputId":"e46cf9e5-f294-44dc-913e-2f87d9f32866"},"outputs":[],"source":["df_customers = dataframes['customers']\n","print(\"\\nColumnas de Clientes:\")\n","print(df_customers.columns.tolist())"]},{"cell_type":"markdown","metadata":{"id":"cH8MAWet2p-6"},"source":["El customer_id es único por pedido. El customer_unique_id es único por persona. Esta es la clave para identificar a un cliente que vuelve.\n","\n","Vamos a unirlos:\n","Un DataFrame que combina la información del pedido (cuándo se hizo, su estado) con la información del cliente (de qué ciudad es, cuál es su ID único)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"elapsed":277,"status":"ok","timestamp":1762185203374,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"i15n42fR2q05","outputId":"a955600e-04d9-47b1-bedf-715cb0f1218f"},"outputs":[],"source":["# Unir pedidos con clientes usando la clave 'customer_id'\n","# Usamos un 'left' merge para asegurar que mantenemos todos los pedidos,\n","# incluso si (hipotéticamente) a alguno le faltara un cliente.\n","\n","df_master = pd.merge(\n","    left=df_orders,\n","    right=df_customers,\n","    on=\"customer_id\",\n","    how=\"left\"\n",")\n","\n","# Muestra el resultado\n","print(\"\\n--- DataFrame Maestro (Pedidos + Clientes) ---\")\n","display(df_master.head())\n","\n","print(f\"Filas en Pedidos: {len(df_orders)}\")\n","print(f\"Filas en Master:  {len(df_master)}\")"]},{"cell_type":"markdown","metadata":{"id":"YUiW7KVRTTg2"},"source":["# Paso 5: Agregar el Valor del Pedido (Payments)\n","Aquí nos encontramos con nuestro primer gran desafío de \"Big Data\" que requiere una decisión estratégica.\n","\n","El Problema: No podemos hacer un merge simple de df_master con dataframes['order_payments']. ¿Por qué? Porque un solo pedido (order_id) puede tener múltiples métodos de pago. Por ejemplo, un cliente puede pagar 100€ usando 80€ de tarjeta de crédito y 20€ de un vale (voucher). Esto resultaría en dos filas para el mismo pedido en la tabla order_payments.\n","\n","La Trampa: Si hiciéramos un merge directo, duplicaríamos filas en nuestro df_master, y al sumar el dinero, ¡contaríamos el pedido varias veces!\n","\n","La Solución Profesional: Primero pre-agregamos la tabla order_payments. La \"colapsamos\" para que tenga solo una fila por order_id que contenga la suma de todo el valor pagado."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":485},"executionInfo":{"elapsed":162,"status":"ok","timestamp":1762185203537,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"H1BtS1DITaSk","outputId":"c9efc6e4-e4a6-4033-a854-29a0c7d725b0"},"outputs":[],"source":["# --- 5.1: Pre-agregar la tabla de Pagos ---\n","\n","# Cargar la tabla de pagos desde nuestro diccionario\n","df_payments = dataframes['order_payments']\n","\n","print(\"--- Pagos (Original) ---\")\n","print(f\"Filas en 'payments': {len(df_payments)}\")\n","display(df_payments.head()) # Puedes descomentar esto para verla\n","\n","# Agrupar por 'order_id' y sumar el 'payment_value'\n","# .reset_index() convierte la salida de groupby de nuevo en un DataFrame\n","df_payments_agg = df_payments.groupby('order_id')['payment_value'].sum().reset_index()\n","\n","# Renombramos la columna para que sea más clara\n","df_payments_agg = df_payments_agg.rename(columns={'payment_value': 'total_payment_value'})\n","\n","print(\"\\n--- Pagos (Agregados por Pedido) ---\")\n","print(f\"Filas en 'payments_agg': {len(df_payments_agg)}\")\n","display(df_payments_agg.head())"]},{"cell_type":"markdown","metadata":{"id":"pUkuTGOVT1_9"},"source":["# 5.2: Unir los Pagos a df_master\n","Ahora que tenemos una tabla limpia con una fila por pedido, podemos unirla a df_master de forma segura."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"elapsed":71,"status":"ok","timestamp":1762185203609,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"ALOqyxRZT36L","outputId":"44471fbe-3f30-4251-99c0-60ba69d6cac5"},"outputs":[],"source":["# --- 5.2: Unir los pagos agregados a nuestro df_master ---\n","\n","print(f\"Filas en df_master (antes del merge): {len(df_master)}\")\n","\n","# Usamos 'how=\"left\"' para mantener todos nuestros pedidos,\n","# incluso si alguno (hipotéticamente) no tuviera pago registrado.\n","df_master = pd.merge(\n","    left=df_master,\n","    right=df_payments_agg,\n","    on=\"order_id\",\n","    how=\"left\"\n",")\n","\n","print(f\"Filas en df_master (después del merge): {len(df_master)}\")\n","print(\"\\n--- DataFrame Maestro (con info de Pagos) ---\")\n","display(df_master.head())"]},{"cell_type":"markdown","metadata":{"id":"REj4NZoRheZ2"},"source":["# Paso 6: Agregar los Productos del Pedido (Items)\n","Este paso es muy similar al de los pagos y es fundamental que entiendas la estrategia.\n","\n","El Problema: La tabla dataframes['order_items'] tiene una fila por cada producto dentro de un pedido. Si un cliente compró 3 productos en un solo pedido (order_id), habrá 3 filas en esta tabla para ese pedido.\n","\n","La Trampa: Si hiciéramos un merge simple de df_master con order_items, nuestro df_master (que con tanto esfuerzo mantuvimos en 99,441 filas) se multiplicaría y tendríamos filas duplicadas de pedidos.\n","\n","La Solución Profesional: De nuevo, pre-agregamos la tabla order_items. La \"colapsaremos\" para que tenga solo una fila por order_id que resuma la información de los productos."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":485},"executionInfo":{"elapsed":106,"status":"ok","timestamp":1762185203717,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"GV_7X1klhjkB","outputId":"ed2eb318-1287-4f4f-da03-f5713e2e2927"},"outputs":[],"source":["# --- 6.1: Pre-agregar la tabla de Items ---\n","\n","# Cargar la tabla de items desde nuestro diccionario\n","df_items = dataframes['order_items']\n","\n","print(\"--- Items (Original) ---\")\n","print(f\"Filas en 'items': {len(df_items)}\")\n","# La columna 'order_item_id' nos dice el número de item (1, 2, 3...)\n","# 'price' es el valor de ESE item\n","# 'freight_value' es el valor del envío de ESE item\n","display(df_items.head())\n","\n","# Agrupar por 'order_id' y realizar múltiples agregaciones\n","df_items_agg = df_items.groupby('order_id').agg(\n","    # Para el num_items, contamos el 'order_item_id' (es como 1, 2, 3...)\n","    num_items=('order_item_id', 'count'),\n","\n","    # Sumamos el precio de todos los items en el pedido\n","    total_product_value=('price', 'sum'),\n","\n","    # Sumamos el envío de todos los items en el pedido\n","    total_freight_value=('freight_value', 'sum')\n",").reset_index() # .reset_index() convierte la salida de groupby en un DataFrame\n","\n","print(\"\\n--- Items (Agregados por Pedido) ---\")\n","print(f\"Filas en 'items_agg': {len(df_items_agg)}\")\n","display(df_items_agg.head())"]},{"cell_type":"markdown","metadata":{"id":"yBpFpvMwh7LS"},"source":["## 6.2: Unir los Items a df_master\n","Ahora que tenemos esta tabla df_items_agg limpia (una fila por pedido), podemos unirla a df_master de forma segura."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"elapsed":175,"status":"ok","timestamp":1762185203894,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"Qg0iv8X8h9vS","outputId":"7dfa7ed9-e924-4b43-a94d-84bf99e098e1"},"outputs":[],"source":["# --- 6.2: Unir los items agregados a nuestro df_master ---\n","\n","print(f\"Filas en df_master (antes del merge): {len(df_master)}\")\n","\n","# Usamos 'how=\"left\"'\n","df_master = pd.merge(\n","    left=df_master,\n","    right=df_items_agg,\n","    on=\"order_id\",\n","    how=\"left\"\n",")\n","\n","print(f\"Filas en df_master (después del merge): {len(df_master)}\")\n","print(\"\\n--- DataFrame Maestro (con info de Items) ---\")\n","display(df_master.head())"]},{"cell_type":"markdown","metadata":{"id":"ApI-BSnwi5xi"},"source":["# Paso 7: Agregar la Categoría del Producto\n","El Problema: Un solo pedido (order_id) puede contener múltiples productos (ej. un par de \"zapatos\" y una \"camiseta\"). Si intentamos unir los productos, obtendremos múltiples filas para un mismo pedido.\n","\n","La Decisión Estratégica: Para nuestro df_master (que queremos mantener como una fila por pedido), no podemos listar todas las categorías. Por lo tanto, tomaremos una decisión de negocio: vamos a identificar el producto \"principal\" de cada pedido y usaremos su categoría.\n","\n","Nuestra Definición de \"Principal\": El producto más caro (price) de ese pedido."]},{"cell_type":"markdown","metadata":{"id":"HhhDIRnKjGU4"},"source":["## 7.1: Identificar el Producto Principal de cada Pedido\n","Vamos a crear una tabla temporal que solo contenga el product_id del item más caro de cada order_id."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"elapsed":164,"status":"ok","timestamp":1762185204059,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"2qCITMocjISE","outputId":"2405ea32-415b-420a-9fe9-30c9827ef6e5"},"outputs":[],"source":["# --- 7.1: Identificar el Producto Principal de cada Pedido ---\n","\n","# Cargar la tabla de items\n","df_items = dataframes['order_items']\n","\n","# 1. Ordenar los items por 'order_id' y luego por 'price' (de mayor a menor)\n","df_items_sorted = df_items.sort_values(by=['order_id', 'price'], ascending=[True, False])\n","\n","# 2. Quedarse solo con la primera fila de cada 'order_id'.\n","# Esto nos da el item más caro de cada pedido.\n","df_main_item = df_items_sorted.drop_duplicates(subset='order_id', keep='first')\n","\n","# 3. Solo necesitamos estas dos columnas para el 'merge'\n","df_main_item_lookup = df_main_item[['order_id', 'product_id']]\n","\n","print(\"--- Tabla de Búsqueda (Pedido -> Producto Principal) ---\")\n","display(df_main_item_lookup.head())\n","print(f\"Filas en 'main_item_lookup': {len(df_main_item_lookup)}\")"]},{"cell_type":"markdown","metadata":{"id":"YTv2Ol6cjVQR"},"source":["## 7.2: Crear una Tabla de Búsqueda de Categorías\n","Ahora, vamos a crear una \"tabla de consulta\" que una product_id -> category_name -> category_name_english."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1762185204063,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"HEJCzGDIjSh1","outputId":"58ab5555-18ad-4ba9-92c3-d6e68623548d"},"outputs":[],"source":["# --- 7.2: Crear Tabla de Búsqueda () ---\n","\n","# Cargar las tablas de productos y de traducción\n","df_products = dataframes['products']\n","df_translation = dataframes['product_category_name_translation']\n","\n","# 1. Unir productos con su traducción al inglés\n","# Solo seleccionamos las columnas que necesitamos para mantenerlo limpio\n","df_categories_en = pd.merge(\n","    left=df_products[['product_id', 'product_category_name']],\n","    right=df_translation,\n","    on='product_category_name',\n","    how='left'\n",")\n","\n","# 2. Solo necesitamos 'product_id' y el nombre en inglés\n","df_category_lookup = df_categories_en[['product_id', 'product_category_name_english']]\n","\n","print(\"--- Tabla de Búsqueda (Producto -> Categoría EN) ---\")\n","display(df_category_lookup.head())"]},{"cell_type":"markdown","metadata":{"id":"9ZhOiKA2jiAi"},"source":["## 7.3: Unir Todo en el df_master\n","Ahora tenemos todas las piezas del rompecabezas:\n","\n","df_master: Nuestro DataFrame principal (una fila por pedido).\n","\n","df_main_item_lookup: Conecta order_id -> product_id (del item más caro).\n","\n","df_category_lookup: Conecta product_id -> product_category_name_english."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"elapsed":198,"status":"ok","timestamp":1762185204261,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"EaQPfzzkjluP","outputId":"de02c07f-676b-4166-a86c-a8a3d86fb1cc"},"outputs":[],"source":["# --- 7.3: Unir Categorías al DataFrame Maestro ---\n","\n","print(f\"Filas en df_master (antes): {len(df_master)}\")\n","\n","# 1. Unir df_master con el producto principal de cada pedido\n","df_master = pd.merge(\n","    left=df_master,\n","    right=df_main_item_lookup,\n","    on='order_id',\n","    how='left'\n",")\n","\n","# 2. Unir el resultado con la tabla de categorías en inglés\n","df_master = pd.merge(\n","    left=df_master,\n","    right=df_category_lookup,\n","    on='product_id',\n","    how='left'\n",")\n","\n","print(f\"Filas en df_master (después): {len(df_master)}\")\n","print(\"\\n--- DataFrame Maestro (Final - con Categorías) ---\")\n","display(df_master.head())"]},{"cell_type":"markdown","metadata":{"id":"L2138XRZa3tK"},"source":["Primero, necesitamos cargar las librerías que usaremos y el df_master que creamos en el notebook anterior.\n","\n","Importante: Para guardar tu df_master al final del Notebook 01, te recomiendo usar to_parquet() en lugar de .to_csv(). Es mucho más rápido y mantiene los tipos de datos (como fechas) correctamente."]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":476,"status":"ok","timestamp":1762185204738,"user":{"displayName":"Raul Jimenz","userId":"11275528699380086804"},"user_tz":0},"id":"PSltdEOxa3-T"},"outputs":[],"source":["# Guardar en formato Parquet (eficiente)\n","df_master.to_parquet(DATA_DIR + \"df_master_transaccional.parquet\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP6iHme/bBNfwf9VsHedzM9","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.14.0"}},"nbformat":4,"nbformat_minor":0}
